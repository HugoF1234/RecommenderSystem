# Guide de DÃ©ploiement sur Render avec Base de DonnÃ©es

## ğŸ“‹ ProblÃ¨me : Les CSV ne sont pas sur GitHub

C'est **normal** ! Les fichiers CSV sont dans `.gitignore` car ils sont trop volumineux (plusieurs centaines de MB) pour Ãªtre versionnÃ©s sur GitHub.

## ğŸš€ Solutions pour Render

### Option 1 : Uploader les CSV via Render Shell (RecommandÃ©)

1. **Connectez-vous Ã  Render Shell** :
   - Allez sur votre service Render
   - Cliquez sur "Shell" dans le menu
   - Ou utilisez : `render shell <service-name>`

2. **CrÃ©ez les dossiers** :
   ```bash
   mkdir -p data/raw
   ```

3. **Uploader les fichiers CSV** :
   - Utilisez `scp` ou `rsync` depuis votre machine locale :
   ```bash
   # Depuis votre machine locale
   scp data/raw/recipes_clean_full.csv <render-user>@<render-host>:~/data/raw/
   scp data/raw/reviews_clean_full.csv <render-user>@<render-host>:~/data/raw/
   ```
   
   **OU** utilisez l'interface Render pour uploader via le Shell

4. **Chargez les donnÃ©es dans la base de donnÃ©es** :
   ```bash
   python main.py load-db
   ```

### Option 2 : TÃ©lÃ©charger depuis Kaggle sur Render

1. **Configurez Kaggle API sur Render** :
   - Dans Render Dashboard â†’ Environment Variables
   - Ajoutez :
     - `KAGGLE_USERNAME` = votre username Kaggle
     - `KAGGLE_KEY` = votre API key Kaggle

2. **CrÃ©ez un script de setup** :
   ```bash
   # Dans Render Shell
   python main.py download
   python main.py load-db
   ```

### Option 3 : Utiliser un Volume Persistant (Payant)

1. **CrÃ©ez un Volume Persistant** sur Render
2. **Montez-le** dans votre service
3. **Stockez les CSV** dans le volume
4. **Chargez les donnÃ©es** une fois

### Option 4 : Utiliser un Service de Stockage (S3, etc.)

1. **Uploader les CSV** sur S3 ou un service similaire
2. **TÃ©lÃ©charger** au dÃ©marrage de l'API
3. **Charger** dans la base de donnÃ©es

## ğŸ“ Script Automatique pour Render

CrÃ©ez un script qui s'exÃ©cute au build pour tÃ©lÃ©charger et charger les donnÃ©es :

```python
# scripts/setup_render.py
import os
from pathlib import Path
from src.data.loader import DataLoader
from src.data.load_to_db import load_data_to_database

def setup_render():
    """Setup data for Render deployment"""
    # Download from Kaggle if credentials are available
    if os.getenv("KAGGLE_USERNAME") and os.getenv("KAGGLE_KEY"):
        loader = DataLoader()
        try:
            loader.download_dataset("hugofouan/recsys-project-dataset-foodcom")
        except:
            print("Kaggle download failed, using manual upload")
    
    # Load into database
    load_data_to_db()
```

## âœ… Solution RecommandÃ©e pour la DÃ©mo

**Pour une dÃ©mo rapide** :

1. **Localement** : Chargez les donnÃ©es dans la base de donnÃ©es
   ```bash
   python main.py load-db
   ```

2. **Uploader la base de donnÃ©es** sur Render :
   ```bash
   # La base de donnÃ©es SQLite sera dans data/saveeat.db
   # Uploader ce fichier sur Render via Shell
   ```

3. **OU** : Utilisez un service de stockage cloud (Google Drive, Dropbox) et tÃ©lÃ©chargez au dÃ©marrage

## ğŸ”§ Modification du Build pour Render

Vous pouvez modifier `build.sh` pour tÃ©lÃ©charger automatiquement :

```bash
#!/bin/bash
# Build script for Render deployment

set -e

echo "=== Upgrading pip ==="
pip install --upgrade pip setuptools wheel

echo "=== Installing PyTorch CPU ==="
pip install torch>=2.0.0 --index-url https://download.pytorch.org/whl/cpu

echo "=== Installing dependencies ==="
pip install -r requirements.txt

echo "=== Setting up data (if available) ==="
# Try to load data if CSV files exist
if [ -f "data/raw/recipes_clean_full.csv" ] || [ -f "data/raw/recipes.csv" ]; then
    echo "CSV files found, loading into database..."
    python main.py load-db || echo "Data loading failed, will use empty database"
else
    echo "No CSV files found. Please upload data manually or use Kaggle API."
fi

echo "=== Build complete ==="
```

## ğŸ“Œ Note Importante

- La base de donnÃ©es SQLite (`data/saveeat.db`) est aussi dans `.gitignore`
- Sur Render, vous devrez soit :
  - Uploader la DB prÃ©-chargÃ©e
  - OU charger les donnÃ©es via `load-db` aprÃ¨s le dÃ©ploiement
  - OU utiliser PostgreSQL (service sÃ©parÃ© sur Render)

## ğŸ¯ Pour la DÃ©mo

**Solution la plus simple** :
1. Chargez les donnÃ©es localement : `python main.py load-db`
2. Uploader `data/saveeat.db` sur Render via Shell
3. L'API utilisera directement la base de donnÃ©es prÃ©-chargÃ©e

