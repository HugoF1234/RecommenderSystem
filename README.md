# ğŸ³ Save Eat - Recommandation de Recettes Intelligentes

Save Eat est un systÃ¨me de recommandation de recettes basÃ© sur des Graph Neural Networks (GNN) qui transforme les ingrÃ©dients disponibles en suggestions personnalisÃ©es et intelligentes.

## ğŸ“‹ Table des MatiÃ¨res

- [Description du Projet](#description-du-projet)
- [Ã‰quipe](#Ã©quipe)
- [Architecture Technique](#architecture-technique)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [Documentation Technique](#documentation-technique)

## ğŸ“– Description du Projet

Save Eat adresse le dÃ©fi quotidien des Ã©tudiants et jeunes professionnels : "Qu'est-ce que je peux cuisiner avec ce que j'ai ?". Le systÃ¨me combine :

- **Recommandation personnalisÃ©e** basÃ©e sur l'historique utilisateur
- **Awareness contextuelle** (ingrÃ©dients disponibles, temps disponible, prÃ©fÃ©rences alimentaires)
- **Architecture hybride GNN** fusionnant graphes de relations recette-ingrÃ©dient avec embeddings textuels
- **Re-ranking contextuel** pour optimiser les suggestions en temps rÃ©el

### Innovation Technique

1. **Graph Neural Networks** : ModÃ©lisation des relations utilisateurs-recettes-ingrÃ©dients via PyTorch Geometric
2. **Embeddings textuels** : Fusion des caractÃ©ristiques textuelles (titres, descriptions) avec Transformers
3. **Re-ranking contextuel** : RÃ©organisation intelligente basÃ©e sur les contraintes rÃ©elles (ingrÃ©dients, temps, prÃ©fÃ©rences)

## ğŸ‘¥ Ã‰quipe

- **Project Lead (PL)** : Victor Lestrade
- **Data Engineer (DE)** : Matthieu Houette
- **Lead ML Engineer (MLE-Core)** : Hugo Fouan
- **ML Engineer - Ops (MLE-Ops)** : Basile Sorrel
- **Systems Engineer (SE)** : Wadih Ben Abdesselem

## ğŸ—ï¸ Architecture Technique

### Stack Technologique

- **Backend** : Python 3.10+, FastAPI
- **ML Framework** : PyTorch, PyTorch Geometric
- **NLP** : Transformers (Hugging Face)
- **Frontend** : HTML5, JavaScript, Tailwind CSS
- **Database** : PostgreSQL / SQLite
- **Data** : Food.com Cleaned Dataset (Kaggle - RecSys project dataset Food.com)

### Architecture en 3 Couches

1. **Data Layer** : Ingestion, nettoyage, construction de graphes
2. **Recommendation Layer** : ModÃ¨le GNN hybride + re-ranking
3. **Serving Layer** : API FastAPI + Frontend Tailwind CSS

## ğŸš€ Installation et Lancement Rapide

**Temps estimÃ© : 10 minutes**

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip ou conda
- Git
- Compte Kaggle (pour tÃ©lÃ©charger le dataset)

### Guide d'Installation Ã‰tape par Ã‰tape

#### Ã‰tape 1 : Cloner le Repository

```bash
git clone https://github.com/HugoF1234/RecommenderSystem.git
cd RecommenderSystem
```

#### Ã‰tape 2 : CrÃ©er un Environnement Virtuel

```bash
# Option A : Avec venv (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# ou sur Windows :
venv\Scripts\activate

# Option B : Avec conda
conda create -n saveeat python=3.10
conda activate saveeat
```

#### Ã‰tape 3 : Installer les DÃ©pendances

```bash
pip install -r requirements.txt
```

**Note :** Si vous rencontrez des erreurs avec PyTorch, installez-le sÃ©parÃ©ment selon votre systÃ¨me :
```bash
# Pour CPU uniquement
pip install torch torchvision torchaudio

# Pour GPU (CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### Ã‰tape 4 : TÃ©lÃ©charger le Dataset

##### Option A : Avec l'API Kaggle (Automatique)

1. Configurez vos credentials Kaggle :
   - CrÃ©ez un compte sur [Kaggle](https://www.kaggle.com/)
   - TÃ©lÃ©chargez votre `kaggle.json` depuis Account > API
   - Placez-le dans `~/.kaggle/kaggle.json` (macOS/Linux) ou `C:\Users\<username>\.kaggle\kaggle.json` (Windows)

2. TÃ©lÃ©chargez le dataset :
   ```bash
   python main.py download
   ```

##### Option B : TÃ©lÃ©chargement Manuel

1. Allez sur Kaggle et recherchez **"RecSys project dataset Food.com"**
2. TÃ©lÃ©chargez le dataset
3. Extrayez les fichiers **`reviews_clean_full.csv`** et **`recipes_clean_full.csv`** dans `data/raw/`
   
   **Note:** Le systÃ¨me utilise maintenant le dataset nettoyÃ© pour de meilleurs rÃ©sultats. Si les fichiers nettoyÃ©s ne sont pas disponibles, le systÃ¨me essaiera automatiquement de charger les fichiers originaux (`reviews.csv` et `recipes.csv`) en fallback.

#### Ã‰tape 5 : PrÃ©parer les DonnÃ©es

```bash
python main.py preprocess
```

Cela va nettoyer les donnÃ©es, extraire les caractÃ©ristiques et crÃ©er les fichiers nÃ©cessaires dans `data/processed/`.

**Temps estimÃ© :** 2-5 minutes selon la taille du dataset.

#### Ã‰tape 6 : Lancer le SystÃ¨me

```bash
python main.py serve
```

Le serveur dÃ©marre sur `http://localhost:8000`

**C'est tout !** Vous pouvez maintenant ouvrir votre navigateur et accÃ©der Ã  :
- **Interface utilisateur :** http://localhost:8000
- **Documentation API :** http://localhost:8000/docs

## ğŸ’» Utilisation

### DÃ©marrer le SystÃ¨me

```bash
python main.py serve
```

L'API sera accessible sur `http://localhost:8000`

- **Frontend (Interface utilisateur) :** http://localhost:8000
- **Documentation API interactive :** http://localhost:8000/docs
- **Health check :** http://localhost:8000/health

### Utiliser le Frontend

1. Ouvrez votre navigateur
2. AccÃ©dez Ã  `http://localhost:8000`
3. SÃ©lectionnez vos ingrÃ©dients disponibles
4. Optionnel : SpÃ©cifiez un temps maximum (minutes)
5. Optionnel : SÃ©lectionnez vos prÃ©fÃ©rences alimentaires (VÃ©gÃ©tarien, VÃ©gan, Sans gluten, Sans lactose)
6. Cliquez sur "Chercher des Recettes"
7. Cliquez sur "Voir la recette" pour afficher les dÃ©tails complets

### Tester l'API directement

```bash
# Exemple de requÃªte de recommandation
curl -X POST "http://localhost:8000/api/v1/recommend" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "available_ingredients": ["tomato", "pasta", "cheese"],
    "max_time": 30,
    "dietary_preferences": ["vegetarian"],
    "top_k": 10
  }'
```

### 4. EntraÃ®ner le ModÃ¨le (Optionnel)

Si vous souhaitez entraÃ®ner le modÃ¨le GNN depuis zÃ©ro :

```bash
python main.py train
```

**Note importante :** Le systÃ¨me fonctionne sans modÃ¨le entraÃ®nÃ© en utilisant des recommandations basÃ©es sur la popularitÃ© et les ingrÃ©dients. L'entraÃ®nement du modÃ¨le GNN est optionnel mais recommandÃ© pour obtenir des recommandations personnalisÃ©es.

**Pour entraÃ®ner le modÃ¨le manuellement** (si `python main.py train` n'est pas encore implÃ©mentÃ©) :

1. CrÃ©ez un script Python ou utilisez un notebook Jupyter :
```python
from src.data.loader import DataLoader
from src.data.preprocessing import DataPreprocessor
from src.data.graph_builder import GraphBuilder
from src.models.gnn_model import HybridGNN
from src.training.train import Trainer
import torch
import yaml
from pathlib import Path

# Load config
with open("config/config.yaml", "r") as f:
    config = yaml.safe_load(f)

# Load processed data
loader = DataLoader()
data = loader.load_all()
preprocessor = DataPreprocessor()
processed_data = preprocessor.process(data["interactions"], data["recipes"])

# Build graph
graph_builder = GraphBuilder(embedding_dim=config["graph"]["embedding_dim"])
graph_data = graph_builder.build_hetero_graph(
    processed_data["train"],
    processed_data["recipes"],
    processed_data["mappings"]
)

# Initialize model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = HybridGNN(
    embedding_dim=config["graph"]["embedding_dim"],
    hidden_dim=config["model"]["gnn"]["hidden_dim"],
    num_layers=config["model"]["gnn"]["num_layers"],
    dropout=config["model"]["gnn"]["dropout"]
)
model.initialize_embeddings(
    processed_data["stats"]["n_users"],
    processed_data["stats"]["n_recipes"],
    device
)

# Train
trainer = Trainer(
    model=model,
    train_data=processed_data,
    val_data=processed_data,
    config=config["training"],
    device=device
)

history = trainer.train(
    graph_data=graph_data,
    save_path=Path(config["training"]["save_path"])
)
```

Le modÃ¨le entraÃ®nÃ© sera sauvegardÃ© dans `models/checkpoints/best_model.pt` et sera automatiquement chargÃ© par l'API au prochain dÃ©marrage.

## ğŸ“ Structure du Projet

```
Project/
â”œâ”€â”€ README.md                      # Ce fichier
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ main.py                        # Point d'entrÃ©e principal (CLI)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                # Configuration (hyperparamÃ¨tres, chemins)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Dataset brut (Food.com)
â”‚   â”œâ”€â”€ processed/                 # DonnÃ©es prÃ©processÃ©es
â”‚   â””â”€â”€ saveeat.db                 # Base de donnÃ©es SQLite (crÃ©Ã©e automatiquement)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ checkpoints/               # ModÃ¨les entraÃ®nÃ©s (.pt)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py              # Chargement du dataset
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # PrÃ©processing des donnÃ©es
â”‚   â”‚   â””â”€â”€ graph_builder.py       # Construction du graphe
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gnn_model.py           # Architecture GNN hybride
â”‚   â”‚   â”œâ”€â”€ text_encoder.py        # Encoder textuel (Transformers)
â”‚   â”‚   â””â”€â”€ reranker.py            # Re-ranking contextuel
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py               # Boucle d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ evaluation.py          # MÃ©triques (NDCG@10, Recall@20, MRR)
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py                # Application FastAPI
â”‚       â”œâ”€â”€ endpoints.py           # Endpoints API
â”‚       â””â”€â”€ database.py              # Gestion base de donnÃ©es
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                 # Interface utilisateur
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ app.js                 # Logique frontend
â””â”€â”€ notebooks/
    â””â”€â”€ exploration.ipynb          # Exploration des donnÃ©es
```

## ğŸ“š Documentation Technique

### Endpoints API

#### POST `/api/v1/recommend`

Obtenir des recommandations de recettes pour un utilisateur.

**Body:**
```json
{
  "user_id": 1,
  "available_ingredients": ["tomate", "pÃ¢tes", "fromage"],
  "max_time": 30,
  "dietary_preferences": ["vegetarian"],
  "top_k": 10
}
```

**Response:**
```json
{
  "recipe_ids": [123, 456, 789, ...],
  "scores": [0.95, 0.89, 0.82, ...],
  "explanations": ["RecommandÃ©: ...", ...]
}
```

#### POST `/api/v1/log_interaction`

Logger une interaction utilisateur-recette.

**Body:**
```json
{
  "user_id": 1,
  "recipe_id": 123,
  "interaction_type": "click",
  "rating": 4.5,
  "available_ingredients": ["tomate", "pÃ¢tes"]
}
```

#### GET `/api/v1/user/{user_id}/interactions`

Obtenir l'historique des interactions d'un utilisateur.

### MÃ©triques d'Ã‰valuation

- **NDCG@10** : Normalized Discounted Cumulative Gain Ã  10
- **Recall@20** : Rappel Ã  20 recommandations
- **MRR** : Mean Reciprocal Rank

### Configuration

Les hyperparamÃ¨tres sont configurables dans `config/config.yaml` :

- ParamÃ¨tres du modÃ¨le GNN
- ParamÃ¨tres d'entraÃ®nement (batch size, learning rate, etc.)
- ParamÃ¨tres de la base de donnÃ©es
- ParamÃ¨tres de l'API

## âœ… VÃ©rification Rapide

Pour vÃ©rifier que tout fonctionne correctement :

```bash
# 1. VÃ©rifier que Python est installÃ©
python --version  # Doit Ãªtre 3.10+

# 2. VÃ©rifier que les dÃ©pendances sont installÃ©es
pip list | grep torch
pip list | grep fastapi

# 3. VÃ©rifier que les donnÃ©es sont prÃ©processÃ©es
ls data/processed/train.csv data/processed/recipes.csv

# 4. Tester le serveur
python main.py serve
# Dans un autre terminal :
curl http://localhost:8000/health
# Devrait retourner : {"status":"healthy"}
```

## ğŸ› DÃ©pannage

### L'API ne dÃ©marre pas

- VÃ©rifiez que le port 8000 n'est pas utilisÃ© : `lsof -i :8000` (macOS/Linux)
- VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es : `pip list`

### Le modÃ¨le n'est pas trouvÃ©

- Le modÃ¨le doit Ãªtre entraÃ®nÃ© d'abord ou tÃ©lÃ©chargÃ©
- VÃ©rifiez que `models/checkpoints/best_model.pt` existe
- L'API fonctionnera sans modÃ¨le mais les recommandations ne fonctionneront pas

### Erreur de dataset

- VÃ©rifiez que les fichiers sont dans `data/raw/`
- VÃ©rifiez les noms de fichiers (peuvent varier selon la version du dataset)

## ğŸš€ DÃ©ploiement

### DÃ©ploiement Local (RecommandÃ© pour la dÃ©mo)

Le systÃ¨me fonctionne parfaitement en local. Pour permettre l'accÃ¨s depuis d'autres machines sur le mÃªme rÃ©seau :

1. DÃ©marrez le serveur avec l'option `--host 0.0.0.0` :
```bash
python main.py serve --host 0.0.0.0
```

2. Trouvez l'adresse IP locale de votre machine :
```bash
# macOS/Linux
ifconfig | grep "inet " | grep -v 127.0.0.1

# Windows
ipconfig
```

3. AccÃ©dez depuis une autre machine sur le mÃªme rÃ©seau WiFi :
```
http://VOTRE_IP_LOCALE:8000
```

### DÃ©ploiement Cloud (Optionnel)

Pour un dÃ©ploiement cloud, plusieurs options sont disponibles :

#### Google Cloud Run (RecommandÃ© - Free Tier gÃ©nÃ©reux)

1. CrÃ©ez un `Dockerfile` :
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py", "serve", "--host", "0.0.0.0", "--port", "8080"]
```

2. DÃ©ployez avec Cloud Run :
```bash
gcloud run deploy saveeat --source . --platform managed
```

#### Heroku (Alternative simple)

1. CrÃ©ez un `Procfile` :
```
web: python main.py serve --host 0.0.0.0 --port $PORT
```

2. DÃ©ployez :
```bash
heroku create saveeat
git push heroku main
```

**Note :** Le dÃ©ploiement cloud est optionnel. Un dÃ©ploiement local fonctionnel est parfaitement acceptable pour ce projet.

## ğŸ“Š RÃ©sumÃ© des Commandes

```bash
# TÃ©lÃ©charger le dataset
python main.py download

# PrÃ©processer les donnÃ©es
python main.py preprocess

# EntraÃ®ner le modÃ¨le (optionnel)
python main.py train

# Lancer le serveur
python main.py serve

# Lancer avec rechargement automatique (dÃ©veloppement)
python main.py serve --reload

# Voir toutes les commandes
python main.py --help
```

## âš¡ Quick Start (RÃ©sumÃ© Ultra-Rapide)

Pour les personnes pressÃ©es qui veulent lancer le projet en 10 minutes :

```bash
# 1. Installation
git clone https://github.com/HugoF1234/RecommenderSystem.git
cd RecommenderSystem
python -m venv venv && source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 2. DonnÃ©es (si pas dÃ©jÃ  fait)
python main.py download && python main.py preprocess

# 3. Lancer
python main.py serve
# Ouvrir http://localhost:8000
```

**C'est tout !** Le systÃ¨me est maintenant accessible.

---

**Note** : Ce projet est rÃ©alisÃ© dans le cadre du cours "RecSys Startup Sprint" par l'Ã©quipe Save Eat.

